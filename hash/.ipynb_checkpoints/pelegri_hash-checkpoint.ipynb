{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Julien Pelegri hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal : play around with hash funcitons, build some and encode some .txt file. Try to optimize time and space complexity and have as few collision as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"hash.png\",width=400,height=400>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Hash test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash for 181 is: 181\n",
      "Hash for 181.23 is: 530343892119126197\n",
      "Hash for Python is: -1700120063019413485\n"
     ]
    }
   ],
   "source": [
    "# hash for integer unchanged\n",
    "print('Hash for 181 is:', hash(181))\n",
    "\n",
    "# hash for decimal\n",
    "print('Hash for 181.23 is:',hash(181.23))\n",
    "\n",
    "# hash for string\n",
    "print('Hash for Python is:', hash('Python'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the file first "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have create a smaller .txt file with only a to go faster when testing since the file is long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of the file:word.txt\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "inputFile = input(\"Enter the name of the file:\")\n",
    "\n",
    "f=open(inputFile, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='word.txt' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "print(f)\n",
    "txt = f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now read the file line per line :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(file):\n",
    "    words =[] #Liste pour stocker les diff√©rentes lignes\n",
    "    # Use str.rstrip() to remove a trailing newline \n",
    "    countword = 0\n",
    "\n",
    "    for line in f:\n",
    "        countword += 1\n",
    "        words.append(line.rstrip(\"\\n\"))\n",
    "    print(countword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "count(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'a', 'aa', 'aal', 'aalii', 'aam', 'aani', 'aardvark', 'aardwolf', 'aaron', 'aaronic', 'aaronical', 'aaronite', 'aaronitic', 'aaru', 'ab', 'aba', 'ababdeh', 'ababua', 'abac', 'abaca', 'abacate', 'abacay', 'abacinate', 'abacination', 'abaciscus', 'abacist', 'aback', 'abactinal', 'abactinally', 'abaction', 'abactor', 'abaculus', 'abacus', 'abadite', 'abaff', 'abaft', 'abaisance', 'abaiser', 'abaissed', 'abalienate', 'abalienation', 'abalone', 'abama', 'abampere', 'abandon', 'abandonable', 'abandoned', 'abandonedly', 'abandonee', 'abandoner', 'abandonment', 'abanic', 'abantes', 'abaptiston', 'abarambo', 'abaris', 'abarthrosis', 'abarticular', 'abarticulation', 'abas', 'abase', 'abased', 'abasedly', 'abasedness', 'abasement', 'abaser', 'abasgi', 'abash', 'abashed', 'abashedly', 'abashedness', 'abashless', 'abashlessly', 'abashment', 'abasia', 'abasic', 'abask', 'abassin', 'abastardize', 'abatable', 'abate', 'abatement', 'abater', 'abatis', 'abatised', 'abaton', 'abator', 'abattoir', 'abatua', 'abature', 'abave', 'abaxial', 'abaxile', 'abaze', 'abb', 'abba', 'abbacomes', 'abbacy', 'abbadide']\n"
     ]
    }
   ],
   "source": [
    "print(words[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(words[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now going through words array and hash it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sha512', 'shake_256', 'sha3_384', 'whirlpool', 'md4', 'ripemd160', 'blake2s256', 'sha3_256', 'sha3_224', 'blake2s', 'mdc2', 'sha3-256', 'sha256', 'sm3', 'shake_128', 'sha224', 'sha3_512', 'md5-sha1', 'md5', 'sha512-224', 'sha512-256', 'blake2b', 'sha3-384', 'blake2b512', 'sha1', 'shake256', 'sha3-512', 'shake128', 'sha384', 'sha3-224'}\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "print(hashlib.algorithms_available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic python hash : use the hash function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1985995106256316638, -1985995106256316638, -2522260873148329644, -7779214016121528904, -2187879817963656670, 5543904849762900652, -5020302775887386427, -1991122141154496668, -1847057614942963390, -1843145911674511092, 4333283369762378169, 1885786175339762779, -3382514097763195589, -3229661217647173278, -625027738066084579, 3482409250133710271, -3479241496061448456, -5178375034155827103, -1152082049267023425, -6173988465505669572, -2152055121479420988, 1851890280589227646, -5907444576319218424, -2399723063590654858, 1396130931617096624, 4868093429915703124, 5045342612022229094, 6624815273205359156, -9214134581610718752, 3798419373101786809, 3958222036461550408, 1587247864478970177, 3494186758934743768, 5294511489477795081, 6083869995181319571, 3427063930314590150, 1486921729203402644, 3679499333360903826, -1522474553112023009, 8044252337515633661, 5269434777963902126, -7969805647609572217, -5196989550908874782, 6371322026349566458, 4218586322483831555, 7868149477104645106, 4875575315427957214, -5250838877017889500, -6433502624872149952, -6923749472982434904, -2826680522759228237, -2581037947106785890, -8247623116472283849, -2791870722263952483, 672391693606657016, -7869518957989353103, 1897743398679277625, 4262904012121070914, -4373275194612281964, 1532876534433110080, -6538487250509490120, -8679783362994690491, -500210605357123266, -8580288789235066014, -3824293197305870903, 2214708014105857668, -3090485620585854270, -4857229914968549153, -5885701834749446821, 1437441875726709291, -7853458944615326228, 3532366664731847057, 532252711868940160, -3069651810692257751, 7576608930503732089, -1169709683356402941, -644417671722204962, -1584919710204851165, 3127120236738659032, 1093706746833853154, -7773312576099041258, 5858715197020039554, 8354622438984878903, -263560397156314891, -6487946792281832917, 4668344500124206940, 5239968975062800536, 7543173000915950535, 6833937546709598432, 5379804257366090929, 5683594589467671960, 6221789909814330193, -1768400545030140512, 5253036054472051868, -8821689329247137258, -8217112375522045271, -7378995179081054714, -1488146474971272538, 8879981920258215840, -4926417381278758097]\n"
     ]
    }
   ],
   "source": [
    "hashed = []\n",
    "for i in words:\n",
    "    hashed.append(hash(i))\n",
    "    \n",
    "print(hashed[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic counting collision, just to have an idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in hashed:\n",
    "    counter +=  hashed.count(i)\n",
    "    \n",
    "# since all elements are already in the array\n",
    "print(counter - len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a basic hash : coding each letter by its in the alphabet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_lowercase\n",
    "\n",
    "\n",
    "LETTERS = {letter: str(index) for index, letter in enumerate(ascii_lowercase, start=1)} \n",
    "\n",
    "def alphabet_position(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    numbers = [LETTERS[character] for character in text if character in LETTERS]\n",
    "\n",
    "    return ' '.join(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abandoner\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1 2 1 14 4 15 14 5 18'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(words[50])\n",
    "alphabet_position(words[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '1', '1 1', '1 1 12', '1 1 12 9 9', '1 1 13', '1 1 14 9', '1 1 18 4 22 1 18 11', '1 1 18 4 23 15 12 6', '1 1 18 15 14', '1 1 18 15 14 9 3', '1 1 18 15 14 9 3 1 12', '1 1 18 15 14 9 20 5', '1 1 18 15 14 9 20 9 3', '1 1 18 21', '1 2', '1 2 1', '1 2 1 2 4 5 8', '1 2 1 2 21 1', '1 2 1 3', '1 2 1 3 1', '1 2 1 3 1 20 5', '1 2 1 3 1 25', '1 2 1 3 9 14 1 20 5', '1 2 1 3 9 14 1 20 9 15 14', '1 2 1 3 9 19 3 21 19', '1 2 1 3 9 19 20', '1 2 1 3 11', '1 2 1 3 20 9 14 1 12', '1 2 1 3 20 9 14 1 12 12 25', '1 2 1 3 20 9 15 14', '1 2 1 3 20 15 18', '1 2 1 3 21 12 21 19', '1 2 1 3 21 19', '1 2 1 4 9 20 5', '1 2 1 6 6', '1 2 1 6 20', '1 2 1 9 19 1 14 3 5', '1 2 1 9 19 5 18', '1 2 1 9 19 19 5 4', '1 2 1 12 9 5 14 1 20 5', '1 2 1 12 9 5 14 1 20 9 15 14', '1 2 1 12 15 14 5', '1 2 1 13 1', '1 2 1 13 16 5 18 5', '1 2 1 14 4 15 14', '1 2 1 14 4 15 14 1 2 12 5', '1 2 1 14 4 15 14 5 4', '1 2 1 14 4 15 14 5 4 12 25', '1 2 1 14 4 15 14 5 5', '1 2 1 14 4 15 14 5 18', '1 2 1 14 4 15 14 13 5 14 20', '1 2 1 14 9 3', '1 2 1 14 20 5 19', '1 2 1 16 20 9 19 20 15 14', '1 2 1 18 1 13 2 15', '1 2 1 18 9 19', '1 2 1 18 20 8 18 15 19 9 19', '1 2 1 18 20 9 3 21 12 1 18', '1 2 1 18 20 9 3 21 12 1 20 9 15 14', '1 2 1 19', '1 2 1 19 5', '1 2 1 19 5 4', '1 2 1 19 5 4 12 25', '1 2 1 19 5 4 14 5 19 19', '1 2 1 19 5 13 5 14 20', '1 2 1 19 5 18', '1 2 1 19 7 9', '1 2 1 19 8', '1 2 1 19 8 5 4', '1 2 1 19 8 5 4 12 25', '1 2 1 19 8 5 4 14 5 19 19', '1 2 1 19 8 12 5 19 19', '1 2 1 19 8 12 5 19 19 12 25', '1 2 1 19 8 13 5 14 20', '1 2 1 19 9 1', '1 2 1 19 9 3', '1 2 1 19 11', '1 2 1 19 19 9 14', '1 2 1 19 20 1 18 4 9 26 5', '1 2 1 20 1 2 12 5', '1 2 1 20 5', '1 2 1 20 5 13 5 14 20', '1 2 1 20 5 18', '1 2 1 20 9 19', '1 2 1 20 9 19 5 4', '1 2 1 20 15 14', '1 2 1 20 15 18', '1 2 1 20 20 15 9 18', '1 2 1 20 21 1', '1 2 1 20 21 18 5', '1 2 1 22 5', '1 2 1 24 9 1 12', '1 2 1 24 9 12 5', '1 2 1 26 5', '1 2 2', '1 2 2 1', '1 2 2 1 3 15 13 5 19', '1 2 2 1 3 25', '1 2 2 1 4 9 4 5']\n"
     ]
    }
   ],
   "source": [
    "encoded = []\n",
    "\n",
    "for i in words:\n",
    "    encoded.append(alphabet_position(i))\n",
    "print(encoded[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in encoded:\n",
    "    counter +=  encoded.count(i)\n",
    "    \n",
    "# since all elements are already in the array\n",
    "print(counter - len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to decode for a given number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphabet_encode(number, alphabet=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"):\n",
    "    \"\"\"Converts an integer to an alphabet equivilent\"\"\"\n",
    "    if not isinstance(number, (int, long)):\n",
    "        raise TypeError(\"number must be an integer\")\n",
    "\n",
    "    if 0 <= number - 1 < len(alphabet):\n",
    "        return alphabet[number - 1]\n",
    "\n",
    "    base = ''\n",
    "    while number != 0:\n",
    "        number, r = divmod(number, len(alphabet))\n",
    "        if r == 0:\n",
    "            number = number - 1\n",
    "        base = alphabet[r - 1] + base\n",
    "    return base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more complex way to hash "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ca978112ca1bbdcafac231b39a23dc4da786eff8147c4e72b9807785afee48bb', 'ca978112ca1bbdcafac231b39a23dc4da786eff8147c4e72b9807785afee48bb', '961b6dd3ede3cb8ecbaacbd68de040cd78eb2ed5889130cceb4c49268ea4d506', '83c54220e5f2c521819cb6d80163858dd6def3c5a9ed37281a532284b342104a', '5c35a11d21fdd9f05512936de142dc0c76bd823d90c748cffe9e9bad684f8c5b', '8e41e925da60505fb2de39f571f058c8cc1a034694d72978c6941c491eb012a8', 'a10b10bddbedcb64b1d0697733ffe31061525dbc2156284ae270550041481a07', 'cf9c1cb89584bf8c4176a37c2c954a8dc56077d3ba65ee44011e62ab7c63ce2d', '7a32f638b2a29765554c3ea7d737c40ac77b9cd9012707e8b1f7956a6b4f722b', '39fdbdb8ddf75a006ffec2a3ba95c3a04ce5517c608a786ef9a042af9843bd8c']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import hashlib\n",
    "\n",
    "hashed = []\n",
    "for i in words:\n",
    "    hashed.append(hashlib.sha256(i.encode('utf-8')).hexdigest())\n",
    "    \n",
    "print(hashed[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'961b6dd3ede3cb8ecbaacbd68de040cd78eb2ed5889130cceb4c49268ea4d506'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashed[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in hashed:\n",
    "    counter +=  hashed.count(i)\n",
    "    \n",
    "# since all elements are already in the array\n",
    "print(counter - len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole process of hashing to a file :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have to re-read the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of the file:word2.txt\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "inputFile = input(\"Enter the name of the file:\")\n",
    "\n",
    "f=open(inputFile, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='word2.txt' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'a', 'aa', 'aal', 'aalii', 'aam', 'aani', 'aardvark', 'aardwolf', 'aaron', 'aaronic', 'aaronical', 'aaronite', 'aaronitic', 'aaru', 'ab', 'aba', 'ababdeh', 'ababua', 'abac', 'abaca', 'abacate', 'abacay', 'abacinate', 'abacination', 'abaciscus', 'abacist', 'aback', 'abactinal', 'abactinally', 'abaction', 'abactor', 'abaculus', 'abacus', 'abadite', 'abaff', 'abaft', 'abaisance', 'abaiser', 'abaissed', 'abalienate', 'abalienation', 'abalone', 'abama', 'abampere', 'abandon', 'abandonable', 'abandoned', 'abandonedly', 'abandonee', 'abandoner', 'abandonment', 'abanic', 'abantes', 'abaptiston', 'abarambo', 'abaris', 'abarthrosis', 'abarticular', 'abarticulation', 'abas', 'abase', 'abased', 'abasedly', 'abasedness', 'abasement', 'abaser', 'abasgi', 'abash', 'abashed', 'abashedly', 'abashedness', 'abashless', 'abashlessly', 'abashment', 'abasia', 'abasic', 'abask', 'abassin', 'abastardize', 'abatable', 'abate', 'abatement', 'abater', 'abatis', 'abatised', 'abaton', 'abator', 'abattoir', 'abatua', 'abature', 'abave', 'abaxial', 'abaxile', 'abaze', 'abb', 'abba', 'abbacomes', 'abbacy', 'abbadide']\n",
      "235886\n"
     ]
    }
   ],
   "source": [
    "count(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtest(fichier):\n",
    "    wn = count(fichier)\n",
    "    table = [0 for i in range(3*wn)]\n",
    "    coll = 0\n",
    "    for mot in f:\n",
    "        h = (hachage1(mot,3*wn) + 3 * hachage2(mot,3*wn) + 2 * hachage3(mot,3*wn))%(3*wn)\n",
    "        if table[h] != 0:\n",
    "            coll = coll+1\n",
    "        table[h] = mot\n",
    "    print(coll,\"collisions sur\",wn,\"mots\")\n",
    "    return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 collisions sur 0 mots\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtest(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def hashtest(fichier):\n",
    "    wn = wordcount(fichier)\n",
    "    table = [0 for i in range(3*wn)]\n",
    "    with open( fichier , \"r\") as f:\n",
    "        coll = 0\n",
    "        for mot in f:\n",
    "            h = (hachage1(mot,3*wn) + 3 * hachage2(mot,3*wn) + 2 * hachage3(mot,3*wn))%(3*wn)\n",
    "            if table[h] != 0:\n",
    "                coll = coll+1\n",
    "            table[h] = mot\n",
    "        print(coll,\"collisions sur\",wn,\"mots\")\n",
    "        return(0)\n",
    "            \n",
    "def hachage1(mot,n):\n",
    "    i = 1\n",
    "    h = 0\n",
    "    l = len(mot)\n",
    "    for car in mot:\n",
    "        h = h+(26**(l-i))*(ord(car) - 96)\n",
    "        i += 1\n",
    "    return (h%n)\n",
    "  \n",
    "def dec2bin(x):\n",
    "    return int(bin(x)[2:])\n",
    "\n",
    "def leftRotate(n, g):\n",
    "    INT_BITS = len(str(dec2bin(n)))\n",
    "    return (n << g)|(n >> (INT_BITS - g)) \n",
    "\n",
    "def rightRotate(n, d):\n",
    "    INT_BITS = len(str(dec2bin(n)))\n",
    "    return (n >> d)|(n << (INT_BITS - d)) & 0xFFFFFFFF\n",
    "\n",
    "def hachage2(mot,n):\n",
    "    i = 1\n",
    "    h = 0\n",
    "    l = len(mot)\n",
    "    for car in mot:\n",
    "        h = h+(26**(l-i))*(ord(car) - 96)\n",
    "        i += 1\n",
    "        h = h >> 1\n",
    "        h = h << 0\n",
    "    return (h%n)\n",
    "\n",
    "def hachage3(mot,n):\n",
    "    i = 1\n",
    "    h = 0\n",
    "    l = len(mot)\n",
    "    for car in mot:\n",
    "        h = h+(26**(l-i))*(ord(car) - 96)\n",
    "        i += 1\n",
    "        h = leftRotate(h,5)\n",
    "    return (h%n)\n",
    "\n",
    "def main():\n",
    "    print(\"Enzo Ostertag - Alejandro Saiz\")\n",
    "    hashtest(\"word2.txt\")\n",
    "    print(\"fin main\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction hashage de Monsieur Lemasquerier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de hachage simple\n",
    "def lemasquerier_bon_hashage(my_str, size):\n",
    "    current=size\n",
    "    n=len(my_str)\n",
    "    toggle = True\n",
    "    for x in range(len(my_str)):\n",
    "        if toggle:\n",
    "            current+=ord(my_str[x])\n",
    "        else:\n",
    "            current*=ord(my_str[x])\n",
    "        toggle = not toggle\n",
    "    current = (current+n)%size\n",
    "    return current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapting my code to Lemasquerier hash function to pass my string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98, 98, 411, 20, 395, 21, 499, 128, 442, 168, 221, 375, 339, 363, 195, 8, 106, 205, 473, 201, 299, 212, 80, 382, 468, 117, 353, 309, 192, 396, 368, 364, 343, 116, 88, 113, 127, 290, 51, 108, 209, 172, 458, 329, 161, 347, 36, 449, 152, 450, 463, 337, 71, 168, 220, 447, 411, 331, 62, 374, 349, 451, 106, 176, 385, 275, 350, 46, 454, 456, 122, 91, 319, 112, 245, 156, 56, 457, 417, 122, 326, 54, 245, 92, 101, 108, 496, 232, 334, 311, 18, 260, 220, 328, 172, 107, 92, 90, 133, 348, 208, 321, 457, 110, 344, 460, 191, 130, 301, 26, 165, 468, 267, 41, 433, 263, 372, 278, 319, 17, 88, 190, 395, 403, 178, 324, 242, 198, 476, 237, 170, 473, 142, 454, 256, 328, 492, 162, 79, 332, 156, 170, 199, 216, 345, 255, 444, 143, 288, 146, 166, 318, 490, 433, 306, 107, 273, 484, 122, 150, 386, 110, 493, 498, 279, 132, 391, 288, 204, 158, 60, 162, 123, 234, 388, 284, 284, 484, 18, 194, 117, 482, 108, 293, 398, 300, 80, 397, 136, 156, 392, 388, 220, 168, 303, 282, 280, 484, 416, 304, 331, 229, 422, 451, 347, 127, 463, 337, 208, 392, 176, 329, 79, 459, 195, 220, 226, 236, 122, 318, 282, 177, 206, 420, 210, 160, 154, 191, 215, 331, 343, 345, 441, 452, 252, 178, 333, 254, 265, 265, 393, 421, 100, 441, 416, 318, 104, 60, 271, 172, 360, 474, 424, 470, 475, 22, 292, 482, 370, 402, 491, 70, 402, 236, 158, 282, 258, 122, 470, 408, 250, 324, 182, 387, 310, 268, 372, 125, 193, 120, 369, 172, 320, 138, 320, 226, 24, 202, 139, 80, 381, 141, 399, 334, 454, 460, 378, 84, 67, 80, 418, 123, 253, 196, 435, 306, 186, 18, 138, 473, 493, 353, 260, 51, 75, 223, 418, 448, 133, 470, 322, 206, 391, 278, 244, 413, 118, 418, 430, 18, 298, 76, 201, 467, 170, 123, 172, 335, 4, 337, 380, 264, 135, 142, 8, 154, 54, 327, 370, 81, 216, 120, 306, 266, 306, 225, 326, 282, 398, 326, 342, 47, 390, 103, 92, 432, 339, 174, 355, 11, 213, 264, 99, 344, 442, 128, 12, 488, 9, 102, 6, 486, 156, 443, 406, 250, 496, 50, 350, 459, 461, 355, 435, 389, 287, 418, 266, 352, 96, 226, 7, 240, 207, 406, 122, 162, 156, 310, 81, 412, 310, 415, 331, 88, 14, 44, 194, 225, 248, 246, 361, 284, 193, 57, 311, 215, 6, 254, 267, 346, 337, 380, 80, 84, 3, 362, 261, 26, 226, 468, 201, 136, 19, 342, 106, 170, 78, 179, 241, 95, 208, 372, 108, 178, 422, 414, 214, 215, 356, 394, 206, 454, 426, 42, 355, 70, 363, 440, 119, 254, 123, 152, 398, 138, 378, 426, 48, 65, 160, 411, 352, 104, 366, 322, 424, 470, 458, 347, 268, 34, 282, 183, 285, 283, 470, 407, 7, 109, 432, 2]\n"
     ]
    }
   ],
   "source": [
    "n = len(words)\n",
    "hash_max = []\n",
    "for i in range(n):\n",
    "    hash_max.append(lemasquerier_bon_hashage(words[i], n))\n",
    "\n",
    "print(hash_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in hash_max:\n",
    "    counter +=  hash_max.count(i)\n",
    "    \n",
    "# since all elements are already in the array\n",
    "print(counter - len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## end of Jupiter Notebook"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Bitcoin_Price_Prediction.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
